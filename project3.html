<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <link rel="stylesheet" href="styles.css" />
  <title>Smart Home UX for Elderly Users | Breanna</title>
</head>
<body>
<header> 
  <img src="images/home_bow.png" alt="Bow graphic" class="bow-top" />
  <nav>
    <ul class="nav-list">
      <li><a href="index.html">Home</a></li>
      <li><a href="work.html">Work</a></li>
      <li><a href="about.html">About</a></li>
      <li><a href="contact.html">Contact</a></li>
      <li>
        <a href="https://drive.google.com/file/d/13WfRjrqAuKIV-VkosvGOBs4YMxhe4Phs/view?usp=sharing" target="_blank" rel="noopener noreferrer">
          Resume
        </a>
      </li>
    </ul>
  </nav>
</header>

<main class="container project-detail">
  <!-- Quick Access -->
  <section class="project-links">
    <h2>Quick Access</h2>
    <p>Want to explore the full case study or click through the design?</p>
    <div class="project-buttons">
      <a href="https://docs.google.com/presentation/d/1xJ1vs9c1-2tPOmZageXLLtv5NZwXqT1ARiAza7dJGTs/edit?usp=sharing" target="_blank" class="button">‡±®‡ßé View Slide Deck</a>
      <a href="https://www.figma.com/design/BowpLwKh25uMn3oOM2R68I/Projects-File?t=4ZGyyhEVN9WXHdgx-1" target="_blank" class="button">ùúóùúö Open Figma Design</a>
    </div>
  </section>

  <!-- Screens Carousel -->
  <section class="case-carousel" aria-label="Smart home screens slideshow">
    <div class="carousel" data-autoplay="true" data-interval="4500">
      <button class="carousel-btn prev" aria-label="Previous slide" title="Previous slide">‚Äπ</button>
      <div class="carousel-viewport" role="region" aria-roledescription="carousel">
        <ul class="carousel-track" aria-live="polite">
          <li class="carousel-slide is-current" aria-roledescription="slide" aria-label="1 of 2">
            <div class="screen-card">
              <a href="images/shh.png" target="_blank" rel="noopener">
                <div class="screen-media">
                  <img src="images/shh.png" alt="Smart home tablet concept: large temperature slider and calming breathing orb" />
                </div>
              </a>
            </div>
          </li>
          <li class="carousel-slide" aria-roledescription="slide" aria-label="2 of 2">
            <div class="screen-card">
              <a href="images/shh2.png" target="_blank" rel="noopener">
                <div class="screen-media">
                  <img src="images/shh2.png" alt="Smart home concept: simple controls, large text, and high-contrast call-to-action" />
                </div>
              </a>
            </div>
          </li>
        </ul>
      </div>
      <button class="carousel-btn next" aria-label="Next slide" title="Next slide">‚Ä∫</button>
    </div>
    <div class="carousel-dots" role="tablist" aria-label="Slides"></div>
  </section>

  <!-- Role & Project Details -->
  <section class="project-section">
    <h2>Role & Project Details</h2>
    <p><strong>Role:</strong> UX Researcher & Designer (Solo)</p>
    <p><strong>Project Type:</strong> 10-page research-driven UX case study and conceptual smart home interface for elderly users</p>
    <p><strong>Timeline:</strong> May 2025</p>
    <p><strong>Focus:</strong> Accessibility, emotional UX, voice user interfaces (VUIs), cross-cultural design, and trust in automation</p>
  </section>

  <!-- Overview -->
  <section class="project-section">
    <h2>Overview</h2>
    <p>
      By 2050, one in six adults worldwide will be over 65. Smart homes promise comfort, safety, and independence‚Äîbut for many older adults, current systems feel confusing, intimidating, or even unsafe. Small touch targets, opaque automation, and cold, robotic interactions can turn ‚Äúsmart‚Äù homes into environments that increase anxiety instead of confidence.
    </p>
    <p>
      This project began as a 10-page research paper on <strong>Smart Home UX for Elderly Users</strong>. I transformed that work into a UX case study that examines how aging, emotion, culture, and trust intersect in smart home environments‚Äîand how we can design interfaces that feel <strong>intuitive, dignifying, and emotionally supportive</strong> instead of overwhelming.
    </p>
    <p>
      Rather than starting from a purely technical perspective, this case study reframes smart home design through a human-centered lens: understanding older adults‚Äô cognitive and physical changes, addressing technophobia, and intentionally shaping voice and visual interfaces that respect autonomy, privacy, and emotional well-being.
    </p>
  </section>

  <!-- Problem Space -->
  <section class="project-section">
    <h2>Problem Space</h2>
    <p>
      Smart devices are increasingly embedded in everyday life‚Äîlighting, thermostats, TVs, security systems, and voice assistants. However, the UX of these systems often assumes younger, tech-comfortable users. For older adults, this mismatch creates friction and exclusion.
    </p>
    <p>
      From my literature review and synthesis, I identified recurring breakdowns in current smart home experiences for elderly users:
    </p>
    <ul>
      <li><strong>Physical barriers:</strong> small touch targets, low contrast, cluttered screens, and interactions that require precise motor control.</li>
      <li><strong>Cognitive barriers:</strong> complex, multi-step flows, hidden states, and interfaces that depend heavily on memory and prior familiarity.</li>
      <li><strong>Emotional barriers:</strong> technophobia, fear of ‚Äúbreaking‚Äù something, and anxiety about being watched or monitored.</li>
      <li><strong>Trust barriers:</strong> unclear data practices, ‚Äúalways listening‚Äù devices, and automation that feels opaque or out of the user‚Äôs control.</li>
      <li><strong>Cultural barriers:</strong> language, tone, and patterns of interaction that reflect Western norms and ignore local expectations or dialects.</li>
    </ul>
    <p>
      As these barriers stack, many older adults disengage from smart home systems altogether‚Äîmissing out on tools that could support safety, independence, and daily comfort.
    </p>
    <p><strong>Guiding Design Question:</strong> How might we create smart home interfaces that are not only accessible and usable for elderly users, but also emotionally supportive, culturally sensitive, and trustworthy?</p>
  </section>

  <!-- Understanding Older Users -->
  <section class="project-section">
    <h2>Understanding Older Users in Smart Environments</h2>
    <p>
      A core insight from the research was that aging is multi-dimensional. It‚Äôs not only about eyesight or mobility; it also involves cognitive changes, emotional context, and lived experience with technology.
    </p>
    <h3>Physical and Cognitive Changes</h3>
    <ul>
      <li><strong>Vision:</strong> reduced visual acuity makes small fonts, low-contrast text, and dense layouts difficult to read.</li>
      <li><strong>Motor control:</strong> arthritis and decreased coordination make tiny buttons and precise gestures frustrating or impossible.</li>
      <li><strong>Cognition:</strong> shorter attention spans, memory challenges, and slower information processing make complex navigation and hidden system states overwhelming.</li>
    </ul>
    <p>
      In many mainstream systems, these realities are treated as edge cases, even though they represent a rapidly growing share of the global population.
    </p>

    <h3>Emotional State & Technophobia</h3>
    <p>
      Emotionally, older adults may feel stressed, self-conscious, or resistant when interacting with unfamiliar technology. This resistance is sometimes labeled as ‚Äútechnophobia,‚Äù but the research shows it is deeply tied to <strong>past experiences, feelings of vulnerability, and concerns about autonomy</strong>.
    </p>
    <p>
      One key pattern: users weren‚Äôt just afraid of pressing the ‚Äúwrong button.‚Äù They were worried about losing control‚Äîbeing monitored, judged, or locked out of their own environment. Poorly designed error states, unexplained system behavior, or confusing voice responses can quickly erode confidence and reinforce the belief that ‚Äúthis isn‚Äôt for me.‚Äù
    </p>

    <h3>Trust and Transparency</h3>
    <p>
      Trust emerged as a recurring theme across sources. When systems:
    </p>
    <ul>
      <li>Explain what they‚Äôre doing in plain language,</li>
      <li>Offer clear and visible privacy controls, and</li>
      <li>Respond consistently and accurately,</li>
    </ul>
    <p>
      older users are more willing to engage and experiment. When those qualities are missing, trust is damaged, and even small failures can feel like proof that smart homes are unsafe or ‚Äútoo advanced.‚Äù
    </p>

    <h3>Inclusive, Participatory Design</h3>
    <p>
      The research also highlighted the importance of <strong>inclusive and participatory design</strong>. Rather than building for older adults in isolation, smart home teams should involve them throughout the process:
    </p>
    <ul>
      <li>Co-design workshops to capture lived experience and mental models.</li>
      <li>Usability testing that includes older participants from early iterations, not just at the end.</li>
      <li>Feedback loops to refine flows, language, and affordances over time.</li>
    </ul>
    <p>
      This approach shifts the mindset from ‚Äúdesigning around limitations‚Äù to <strong>co-creating systems that respect autonomy, dignity, and diversity in aging</strong>.
    </p>
  </section>

  <!-- Voice User Interfaces -->
  <section class="project-section">
    <h2>Voice User Interfaces & Speech-Based Interaction</h2>
    <p>
      Voice user interfaces (VUIs) are often positioned as a perfect solution for older adults: no tiny buttons, no complex menus‚Äîjust speech. The reality is more complicated.
    </p>
    <h3>Opportunities</h3>
    <ul>
      <li>VUIs can remove the need for precise touch or visual scanning.</li>
      <li>Speech is a natural mode of interaction for many older adults.</li>
      <li>Hands-free control is ideal for mobility limitations or multitasking.</li>
    </ul>

    <h3>Barriers in Practice</h3>
    <p>
      Research on elderly users interacting with smart environments revealed several consistent breakdowns:
    </p>
    <ul>
      <li>
        <strong>Speech recognition mismatch:</strong> many assistants struggle with slower speech, regional accents, or non-standard phrasing. Repeated failures quickly lead to frustration and abandonment.
      </li>
      <li>
        <strong>Rigid command structures:</strong> systems often expect specific phrases. If a user says ‚ÄúTurn on the lights in here‚Äù instead of ‚ÄúActivate bedroom lights,‚Äù the request may fail‚Äîeven though the intent is obvious.
      </li>
      <li>
        <strong>Privacy and ‚Äúalways listening‚Äù fears:</strong> older adults worry about who can hear them, what is being recorded, and where that data goes.
      </li>
    </ul>

    <h3>Designing Age-Friendly VUIs</h3>
    <p>
      An age-friendly VUI for smart homes should:
    </p>
    <ul>
      <li>Accept a <strong>range of natural speech patterns</strong> rather than memorized commands.</li>
      <li>Provide <strong>clear feedback</strong> about what was heard and what will happen next.</li>
      <li>Offer <strong>visible, controllable privacy settings</strong> (e.g., microphone on/off states that are obvious and easy to change).</li>
      <li>Handle incomplete or partial commands gracefully instead of ending the interaction abruptly.</li>
      <li>Allow for <strong>slower conversation pacing</strong> and pauses without timing out.</li>
    </ul>
    <p>
      The research also raised the possibility of VUIs providing companionship, not just command execution. Warm tone, friendly greetings, and gentle reminders can shift the experience from ‚Äúcontrolling a device‚Äù to <strong>being supported by a helpful presence</strong>, especially for older adults who live alone.
    </p>
  </section>

  <!-- Cultural Context -->
  <section class="project-section">
    <h2>Cultural Context & Localization</h2>
    <p>
      Designing smart home systems for older adults is not just a question of age‚Äîit‚Äôs also a question of culture. Several studies focused on elderly users in Chinese households, highlighting how <strong>Western-centric design defaults</strong> create serious usability issues.
    </p>
    <h3>Smart TVs & Local Input Methods</h3>
    <p>
      In one study, older Chinese adults struggled with smart TV interfaces built around:
    </p>
    <ul>
      <li>Pinyin-based text entry that assumes familiarity with specific input methods.</li>
      <li>Hierarchical menu systems modeled after tech-savvy users‚Äô mental models.</li>
      <li>Dense layouts and small fonts optimized for younger, more visually comfortable audiences.</li>
    </ul>
    <p>
      The result: tasks that should feel simple, like finding a show or adjusting a setting, became stressful and time-consuming.
    </p>

    <h3>Culturally Aligned Voice Interaction</h3>
    <p>
      Another set of findings showed that VUIs tailored to local norms‚Äîwith honorific language, polite tones, and family-oriented reminders‚Äîwere perceived as more trustworthy and comforting. This goes beyond translation. It includes:
    </p>
    <ul>
      <li>Adapting <strong>voice tone and phrasing</strong> to local expectations of respect and warmth.</li>
      <li>Supporting <strong>regional dialects</strong> instead of a single standard accent.</li>
      <li>Reflecting <strong>local social values</strong> (for example, reminders that reference family or communal responsibility).</li>
    </ul>
    <p>
      These findings reinforce that <strong>cultural localization is a UX decision, not just a language decision</strong>. When cultural context is ignored, even accessible interfaces can feel impersonal or alienating.
    </p>
  </section>

  <!-- Emotional Well-Being -->
  <section class="project-section">
    <h2>Emotional Well-Being & Pleasurable UX</h2>
    <p>
      A central argument in the research is that usability and accessibility are necessary‚Äîbut not sufficient. For elderly users, <strong>emotional experience</strong> can determine whether a system feels empowering or alienating.
    </p>
    <h3>From ‚ÄúJust Works‚Äù to ‚ÄúFeels Good to Use‚Äù</h3>
    <p>
      Studies on emotional UX in smart environments argue that systems should be:
    </p>
    <ul>
      <li><strong>Comforting:</strong> interfaces should feel calm and non-threatening.</li>
      <li><strong>Encouraging:</strong> feedback should reassure users rather than blame them.</li>
      <li><strong>Personally meaningful:</strong> content and interactions should reflect the user‚Äôs life, routines, and preferences.</li>
    </ul>
    <p>
      For older adults who may spend long stretches of time alone at home, smart environments can also become social and emotional touchpoints. Features like shared photos, mood-based music suggestions, or gentle reminders to reach out to loved ones can support mental health.
    </p>

    <h3>Confidence & Error Handling</h3>
    <p>
      Poor UX erodes confidence quickly. Confusing errors or unpredictable behavior can make users feel judged or incompetent. In contrast, designs that:
    </p>
    <ul>
      <li>Offer <strong>gentle prompts</strong> instead of harsh error messages,</li>
      <li>Provide <strong>simple ‚Äúundo‚Äù paths</strong>, and</li>
      <li>Highlight what the user did correctly, not just what went wrong,</li>
    </ul>
    <p>
      help build resilience and trust. Over time, positive emotional experiences make it more likely that users will continue engaging with the system rather than avoiding it.
    </p>

    <h3>Individuality & Personalization</h3>
    <p>
      Emotional needs are not one-size-fits-all. Personality, cultural background, and personal history shape what feels comforting, respectful, or overwhelming. The research suggests that smart home UX should allow older users to personalize:
    </p>
    <ul>
      <li>Voice tone and formality,</li>
      <li>Notification frequency and style,</li>
      <li>Visual themes (contrast, typography size, icon emphasis), and</li>
      <li>Types of reminders (health, social, household, spiritual, etc.).</li>
    </ul>
    <p>
      Personalization here is not a luxury add-on; it is a strategy for emotional alignment and long-term adoption.
    </p>
  </section>

  <!-- Design Framework & Principles -->
  <section class="project-section">
    <h2>Design Framework & Best Practices</h2>
    <p>
      Synthesizing the literature, I created a design framework that can guide smart home UX decisions for elderly users. It organizes needs into primary and secondary layers, similar to a hierarchy of UX needs specific to aging in smart environments.
    </p>
    <h3>Core Principles</h3>
    <ol>
      <li>
        <strong>Simplicity & Clarity</strong><br />
        Interfaces should minimize cognitive load: clean layouts, fewer steps per task, reduced branching, and clear visual hierarchy. Big, high-contrast text and obvious actions are baseline‚Äînot ‚Äúaccessibility extras.‚Äù
      </li>
      <li>
        <strong>Natural Language Support</strong><br />
        Systems should understand natural speech, regional accents, and flexible phrasing rather than expecting memorized command syntax.
      </li>
      <li>
        <strong>Trust & Transparency</strong><br />
        Make data practices visible and controllable. Explain what is happening in clear language and avoid ‚Äúblack box‚Äù automation that changes the home environment without clear feedback.
      </li>
      <li>
        <strong>Cultural Sensitivity</strong><br />
        Localize language, tone, interaction patterns, and content. What works in Western, English-speaking interfaces may not translate to other cultures or age groups.
      </li>
      <li>
        <strong>User Inclusion & Co-Design</strong><br />
        Include older adults from the beginning. Their lived experiences reveal barriers that younger designers and engineers may never notice.
      </li>
      <li>
        <strong>Emotional Engagement</strong><br />
        Design for comfort, reassurance, and joy. Treat emotional well-being as a first-class outcome, not an afterthought.
      </li>
    </ol>
    <p>
      These principles informed the conceptual screens and interaction patterns I created for this project.
    </p>
  </section>

  <!-- Concept Screens & Interaction Patterns -->
  <section class="project-section">
    <h2>Concept Screens & Interaction Patterns</h2>
    <p>
      To translate the research into tangible UX, I designed tablet-based smart home concepts aimed at elderly users. The flows emphasize <strong>calm visuals, linear navigation, and emotionally supportive feedback</strong>.
    </p>

    <h3>1. Temperature Control: Accessible, Glanceable Sliders</h3>
    <p>
      Building on studies that explored older adults‚Äô interaction with prototype temperature sliders, I explored screens with:
    </p>
    <ul>
      <li>Large, thumb-friendly knobs and clear color scales.</li>
      <li>Minimal on-screen elements to keep attention on the main task.</li>
      <li>Clear confirmation states (e.g., ‚ÄúLiving room temperature set to 72¬∞F‚Äù).</li>
    </ul>
    <p>
      The goal is for adjustments to feel <strong>predictable and low-risk</strong>, reducing anxiety that a small mistake will dramatically change the environment.
    </p>

    <h3>2. Breathing Orb: Calming, Humanized Interaction</h3>
    <p>
      Inspired by emotional UX research, I designed a glowing, responsive ‚Äúbreathing orb‚Äù concept that:
    </p>
    <ul>
      <li>Expands and contracts slowly to guide calm breathing.</li>
      <li>Responds to voice commands in a warm, supportive tone.</li>
      <li>Acts as a central anchor on the home screen alongside time and weather.</li>
    </ul>
    <p>
      The orb turns the interface into more than a control panel‚Äîit becomes a small, steady presence that supports <strong>relaxation and emotional grounding</strong>.
    </p>

    <h3>3. Smart Fridge & Medication Concept</h3>
    <p>
      One conceptual pattern from the research is a smart fridge interface that combines:
    </p>
    <ul>
      <li>Large-text reminders for medication schedules.</li>
      <li>Suggested recipes based on what is available and dietary needs.</li>
      <li>Simple icons and limited choices per screen to reduce decision fatigue.</li>
    </ul>
    <p>
      This concept ties functional support (nutrition and medication adherence) with emotional reassurance (‚ÄúYou‚Äôre taking care of yourself, and the system is here to help‚Äù).
    </p>

    <h3>4. Reminders & Check-Ins</h3>
    <p>
      Across screens, reminders are designed to feel <strong>gentle and collaborative</strong>, not nagging:
    </p>
    <ul>
      <li>Friendly copy like ‚ÄúWould you like to take a quick stretch?‚Äù instead of rigid alerts.</li>
      <li>Clear options such as ‚ÄúLater‚Äù or ‚ÄúDone‚Äù with generous targets.</li>
      <li>Optional connection to family or caregiver updates if the user opts in.</li>
    </ul>
    <p>
      The interaction model respects the user‚Äôs autonomy while still offering support and structure.
    </p>
  </section>

  <!-- Limitations -->
  <section class="project-section">
    <h2>Limitations</h2>
    <p>
      This project is intentionally research-driven and conceptual rather than a shipped product. There are several limitations:
    </p>
    <ul>
      <li>
        The insights are based on existing academic studies that often rely on <strong>localized samples</strong>, which limits how broadly findings can be generalized.
      </li>
      <li>
        Many studies captured <strong>one-time interactions</strong> rather than long-term adoption, leaving questions about how relationships with smart homes evolve over months or years.
      </li>
      <li>
        A significant amount of data is <strong>self-reported</strong>, which can miss nuances in real-world behavior and emotional response.
      </li>
      <li>
        My concept work focuses on <strong>tablet and voice interactions</strong> and does not yet extend into every device class (e.g., wearables, in-car systems, or fully multimodal rooms).
      </li>
    </ul>
    <p>
      These limitations point directly to opportunities for future research and iterative design.
    </p>
  </section>

  <!-- Future Directions & Impact -->
  <section class="project-section">
    <h2>Future Directions</h2>
    <p>
      If extended beyond a research case study, the next phase of this work would focus on:
    </p>
    <ul>
      <li>
        <strong>Longitudinal studies:</strong> observing how elderly users actually live with smart home systems over time, not just in short lab sessions.
      </li>
      <li>
        <strong>Broader sampling:</strong> including users across different cultures, income levels, living situations, and levels of tech familiarity.
      </li>
      <li>
        <strong>Co-designed prototypes:</strong> building and testing flows directly with older adults using participatory design methods.
      </li>
      <li>
        <strong>Adaptive personalization:</strong> allowing interfaces to adjust to users‚Äô changing physical, cognitive, and emotional needs as they age.
      </li>
      <li>
        <strong>Interdisciplinary collaboration:</strong> partnering with gerontologists, caregivers, clinicians, and engineers to ensure designs align with real-world constraints and safety needs.
      </li>
    </ul>
    <p>
      Overall, the project argues that age-friendly smart homes require more than ‚Äúbigger buttons.‚Äù They require a shift toward <strong>emotionally intelligent, culturally aware, and deeply inclusive UX</strong>.
    </p>
  </section>

  <!-- Conclusion -->
  <section class="project-section">
    <h2>Conclusion</h2>
    <p>
      As the global population ages, smart homes have the potential to either widen or close the gap of digital exclusion. This project reframes smart home UX for elderly users as a space where accessibility, emotion, culture, and trust all intersect.
    </p>
    <p>
      Through a 10-page research synthesis and concept design work, I explored how physical, cognitive, and emotional realities of aging interact with current smart home systems. The takeaway is simple but powerful: <strong>a good UX meets users where they are</strong>. Voice interfaces, emotional design, and personalization should not be treated as ‚Äúnice-to-haves‚Äù‚Äîthey are fundamental to making smart homes feel like supportive partners rather than confusing, judgmental machines.
    </p>
    <p>
      My main learning as a designer is that designing for older adults is not about reducing ambition. It is about raising the bar for empathy, clarity, and long-term care in the products we build.
    </p>
  </section>

  <!-- References (high-level, portfolio-style) -->
  <section class="project-section">
    <h2>References</h2>
    <p>
      This case study is grounded in academic research on:
    </p>
    <ul>
      <li>Emotional and pleasurable UX in smart environments for older adults.</li>
      <li>Adoption of voice-user interfaces and smart speakers among elderly users, including Chinese populations.</li>
      <li>Usability challenges of smart TVs and smart home systems for older adults, especially around text entry and navigation.</li>
      <li>Trust, transparency, and privacy concerns in speech-based intelligent personal assistants.</li>
      <li>Frameworks for inclusive, human-centered design in aging and assistive technologies.</li>
    </ul>
    <p>
      In the original academic paper, these works were cited formally as [1]‚Äì[5]; here, they are synthesized to support design decisions and frameworks rather than presented in full citation format.
    </p>
  </section>
</main>

<!-- Carousel JS (same as your other projects) -->
<script>
(function () {
  const root = document.querySelector('.case-carousel .carousel');
  if (!root) return;

  const track = root.querySelector('.carousel-track');
  const slides = Array.from(track.children);
  const prevBtn = root.querySelector('.carousel-btn.prev');
  const nextBtn = root.querySelector('.carousel-btn.next');
  const dotsWrap = root.parentElement.querySelector('.carousel-dots');

  slides.forEach((_, i) => {
    const dot = document.createElement('button');
    dot.type = 'button';
    dot.role = 'tab';
    dot.ariaLabel = `Go to slide ${i + 1}`;
    dot.dataset.index = i;
    dotsWrap.appendChild(dot);
  });

  const dots = Array.from(dotsWrap.children);
  let index = 0;

  function update() {
    track.style.transform = `translateX(${index * -100}%)`;
    slides.forEach((s, i) => s.classList.toggle('is-current', i === index));
    dots.forEach((d, i) => d.setAttribute('aria-selected', i === index ? 'true' : 'false'));
  }

  function goTo(i) {
    index = (i + slides.length) % slides.length;
    update();
  }

  prevBtn.addEventListener('click', () => goTo(index - 1));
  nextBtn.addEventListener('click', () => goTo(index + 1));
  dots.forEach(d => d.addEventListener('click', () => goTo(parseInt(d.dataset.index, 10))));

  // Keyboard + swipe
  root.addEventListener('keydown', (e) => {
    if (e.key === 'ArrowLeft') goTo(index - 1);
    if (e.key === 'ArrowRight') goTo(index + 1);
  });
  root.tabIndex = 0;

  let startX = null;
  track.addEventListener('touchstart', (e) => { startX = e.touches[0].clientX; }, { passive: true });
  track.addEventListener('touchmove', (e) => {
    if (startX === null) return;
    const dx = e.touches[0].clientX - startX;
    if (Math.abs(dx) > 50) {
      goTo(index + (dx < 0 ? 1 : -1));
      startX = null;
    }
  }, { passive: true });
  track.addEventListener('touchend', () => { startX = null; });

  // Autoplay
  const autoplay = root.dataset.autoplay === 'true';
  const interval = Number(root.dataset.interval || 4500);
  let timer = null;
  function startAuto() { if (autoplay) timer = setInterval(() => goTo(index + 1), interval); }
  function stopAuto() { if (timer) clearInterval(timer); }
  root.addEventListener('mouseenter', stopAuto);
  root.addEventListener('mouseleave', startAuto);
  document.addEventListener('visibilitychange', () => (document.hidden ? stopAuto() : startAuto()));

  update();
  startAuto();
})();
</script>
</body>
</html>





